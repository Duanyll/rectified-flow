{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from diffusers import FluxPipeline\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from IPython.display import clear_output\n",
    "\n",
    "DTYPE = torch.bfloat16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=DTYPE)\n",
    "pipe.to(device)\n",
    "print(f\"Loaded pipeline to device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.models.flux_dev import FluxWrapper\n",
    "from rectified_flow.rectified_flow import RectifiedFlow\n",
    "from rectified_flow.utils import set_seed\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "height = 1025\n",
    "width = 1025\n",
    "\n",
    "flux_model = FluxWrapper(\n",
    "    pipeline=pipe,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    dtype=DTYPE,\n",
    "    device=device,\n",
    "\tseed=0,\n",
    ")\n",
    "\n",
    "rectflow = RectifiedFlow(\n",
    "    data_shape=flux_model.packed_latent_shape,\n",
    "    model=flux_model,\n",
    "    interp=\"straight\",\n",
    "    device=device,\n",
    "\tdtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and store sampling info for several following samplers\n",
    "X_0 = rectflow.sample_source_distribution(batch_size=1)\n",
    "time_grid = flux_model.prepare_time_grid(num_steps=50)\n",
    "print(f\"X_0: {X_0.shape}\")\n",
    "print(f\"time_grid: {time_grid}\")\t\n",
    "\n",
    "def print_time_callback(sampler): # demo callback function, e.g. one-step prediction\n",
    "    \"\"\"A callback function to print the current time t, refreshing the Jupyter Notebook output.\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Current time: {sampler.t:.4f}\")\n",
    "    \n",
    "my_callback = [print_time_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import rf_samplers_dict\n",
    "\n",
    "for sampler_name, sampler_class in rf_samplers_dict.items():\n",
    "\tprint(f\"Sampler: {sampler_name}, class: {sampler_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import EulerSampler\n",
    "\n",
    "euler_sampler = EulerSampler(\n",
    "    rectified_flow=rectflow,\n",
    "    callbacks=my_callback,\n",
    ")\n",
    "\n",
    "euler_sampler.sample_loop(\n",
    "    X_0=X_0,\n",
    "    time_grid=time_grid,\n",
    "    prompt=\"A photo of a cat holding a camera\",\n",
    "    guidance_scale=3.5,\n",
    ")\n",
    "\n",
    "X_1 = euler_sampler.trajectories[-1]\n",
    "print(X_1.shape)\n",
    "\n",
    "img = flux_model.unpack_and_decode(X_1)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_refresh_sampler = rf_samplers_dict[\"noise_refresh\"](\n",
    "    rectified_flow=rectflow,\n",
    "    callbacks=my_callback,\n",
    ")\n",
    "\n",
    "noise_refresh_sampler.sample_loop(\n",
    "    X_0=X_0,\n",
    "    time_grid=time_grid,\n",
    "    prompt=\"A photo of a cat holding a camera\",\n",
    "    guidance_scale=3.5,\n",
    ")\n",
    "\n",
    "X_1 = noise_refresh_sampler.trajectories[-1]\n",
    "print(X_1.shape)\n",
    "\n",
    "img = flux_model.unpack_and_decode(X_1)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overshoot_sampler = rf_samplers_dict[\"overshooting\"](\n",
    "    rectified_flow=rectflow,\n",
    "    callbacks=my_callback,\n",
    ")\n",
    "\n",
    "overshoot_sampler.sample_loop(\n",
    "    X_0=X_0,\n",
    "    time_grid=time_grid,\n",
    "    prompt=\"A photo of a cat holding a camera\",\n",
    "    guidance_scale=3.5,\n",
    ")\n",
    "\n",
    "X_1 = overshoot_sampler.trajectories[-1]\n",
    "print(X_1.shape)\n",
    "\n",
    "img = flux_model.unpack_and_decode(X_1)\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
