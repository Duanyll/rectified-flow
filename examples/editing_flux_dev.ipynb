{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from diffusers import FluxPipeline\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from IPython.display import clear_output\n",
    "\n",
    "DTYPE = torch.bfloat16\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=DTYPE)\n",
    "pipe.to(device)\n",
    "print(f\"Loaded pipeline to device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.models.flux_dev import FluxWrapper\n",
    "from rectified_flow.rectified_flow import RectifiedFlow\n",
    "from rectified_flow.utils import set_seed\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "height = 1024\n",
    "width = 1024\n",
    "\n",
    "flux_model = FluxWrapper(\n",
    "    pipeline=pipe,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    dtype=DTYPE,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "rectified_flow = RectifiedFlow(\n",
    "    data_shape=flux_model.dit_latent_shape,\n",
    "    velocity_field=flux_model,\n",
    "    interp=\"straight\",\n",
    "    device=device,\n",
    "\tdtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"./assets/editing_cat.png\")\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(1024, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "                transforms.CenterCrop(1024),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "img = train_transforms(img).unsqueeze(0).to(\"cuda\").to(DTYPE)\n",
    "\n",
    "img_latent = flux_model.encode(img)\n",
    "img_rec = flux_model.decode(img_latent)\n",
    "\n",
    "plt.imshow(img_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple noisy interpolation editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the image $X_1$, we first add noise to the image using the equation $X_t = X_1 \\cdot t + (1 - t) \\cdot \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, I)$ represents the mixed noise. We then apply the Euler sampler starting from $X_t$ with the editing target prompt to obtain the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = rectified_flow.sample_source_distribution(1)\n",
    "\n",
    "noisy_time = 0.12\n",
    "t = torch.full((1,), noisy_time)\n",
    "t = rectified_flow.match_dim_with_data(t, img_latent.shape, expand_dim=True)\n",
    "\n",
    "x_t = t * img_latent.clone() + (1 - t) * noise\n",
    "\n",
    "time_grid = torch.linspace(noisy_time, 1, 50).tolist()\n",
    "\n",
    "x_t_rec = flux_model.decode(x_t)\n",
    "plt.imshow(x_t_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple editing tasks, such as turning a cat into a tiger, this straightforward renoising method works effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import EulerSampler\n",
    "\n",
    "sampler = EulerSampler(\n",
    "    rectified_flow=rectified_flow,\n",
    "    time_grid=time_grid,\n",
    ")\n",
    "\n",
    "prompt = \"a photo of a sitting tiger\"\n",
    "\n",
    "x_1 = sampler.sample_loop(x_0=x_t, prompt=prompt, guidance_scale=3.5).trajectories[-1]\n",
    "\n",
    "x_1_rec = flux_model.decode(x_1)\n",
    "plt.imshow(x_1_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for more \"complex\" or larger-scale edits, directly adding noise and then denoising becomes challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photo of a reflective silver cat statue, with a smooth glossy surface\"\n",
    "\n",
    "# Try different noise time, can't achieve ideal result\n",
    "noisy_time = 0.1\n",
    "t = torch.full((1,), noisy_time)\n",
    "t = rectified_flow.match_dim_with_data(t, x_1.shape, expand_dim=True)\n",
    "x_t = t * img_latent.clone() + (1 - t) * noise\n",
    "time_grid = torch.linspace(noisy_time, 1, 50).tolist()\n",
    "\n",
    "x_1 = sampler.sample_loop(x_0=x_t, time_grid=time_grid, prompt=prompt, guidance_scale=3.5).trajectories[-1]\n",
    "\n",
    "x_1_rec = flux_model.decode(x_1)\n",
    "plt.imshow(x_1_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more advanced soft interpolation editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import EulerSampler\n",
    "\n",
    "class EditingVelocityFiled(torch.nn.Module):\n",
    "    def __init__(self, velocity_model, analytic_velocity, start_t, end_t, eta_base, eta_trend, alpha=1.):\n",
    "        self.start_t = start_t\n",
    "        self.end_t = end_t\n",
    "        self.eta_base = eta_base\n",
    "        self.eta_trend = eta_trend\n",
    "        self.alpha = alpha\n",
    "        self.velocity_model = velocity_model\n",
    "        self.analytic_velocity = analytic_velocity\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_eta_value(t, start_t, end_t, eta, eta_trend, alpha):\n",
    "        assert 0 <= start_t < end_t <= 1.0, \"start_t and end_t must be in [0, 1] range, and start_t < end_t\"\n",
    "        assert 0 <= eta <= 1.0, \"eta must be in [0, 1] range\"\n",
    "        if t < start_t or t > end_t:\n",
    "            return torch.tensor(0.0, device=t.device, dtype=t.dtype)\n",
    "        \n",
    "        alpha = torch.tensor(alpha, device=t.device, dtype=t.dtype)\n",
    "        tau = (t - start_t) / (end_t - start_t)\n",
    "        if eta_trend == 'constant':\n",
    "            return eta\n",
    "        elif eta_trend == 'linear_decrease':\n",
    "            return eta * (1 - tau)\n",
    "        elif eta_trend == 'exponential_decrease':\n",
    "            if abs(alpha) < 1e-5:\n",
    "                return eta * (1 - tau)\n",
    "            else:\n",
    "                numerator = torch.exp(alpha * tau) - 1\n",
    "                denominator = torch.exp(alpha) - 1\n",
    "                return eta * (1 - (numerator / denominator))\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unsupported eta_trend: {eta_trend}\")\n",
    "        \n",
    "    def forward(self, x_t, t, **kwargs):\n",
    "        original_velocity = self.velocity_model(x_t, t, **kwargs)\n",
    "        target_velocity = self.analytic_velocity(x_t, t)\n",
    "        \n",
    "        eta = self.get_eta_value(t, self.start_t, self.end_t, self.eta_base, self.eta_trend, self.alpha)\n",
    "\n",
    "        print(f\"Current time: {t.item():.4f}, {eta.item():.4f} * target velocity, {1 - eta.item():.4f} * original velocity\")\n",
    "        \n",
    "        return eta * target_velocity + (1 - eta) * original_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.models.gauss_analytic import AnalyticGaussianVelocity\n",
    "\n",
    "analytic_velocity = AnalyticGaussianVelocity(dataset=img_latent, interp=rectified_flow.interp)\n",
    "\n",
    "editing_velocity_field = EditingVelocityFiled(\n",
    "    velocity_model=flux_model,\n",
    "    analytic_velocity=analytic_velocity,\n",
    "    start_t=0.,\n",
    "    end_t=0.25,\n",
    "    eta_base=0.93,\n",
    "    eta_trend='exponential_decrease',\n",
    "    alpha=2.,\n",
    ")\n",
    "\n",
    "editing_rectified_flow = RectifiedFlow(\n",
    "    data_shape=flux_model.dit_latent_shape,\n",
    "    velocity_field=editing_velocity_field,\n",
    "    interp=\"straight\",\n",
    "    device=device,\n",
    "\tdtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import EulerSampler\n",
    "\n",
    "sampler = EulerSampler(\n",
    "    rectified_flow=editing_rectified_flow,\n",
    "\ttime_grid=time_grid,\n",
    "    num_samples=1,\n",
    ")\n",
    "\n",
    "time_grid = flux_model.prepare_time_grid(28)\n",
    "\n",
    "prompt = \"a photo of a sitting tiger\"\n",
    "\n",
    "x_1 = sampler.sample_loop(seed=0, prompt=prompt, guidance_scale=3.5).trajectories[-1]\n",
    "\n",
    "x_1_rec = flux_model.decode(x_1)\n",
    "plt.imshow(x_1_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import SDESampler\n",
    "\n",
    "time_grid = flux_model.prepare_time_grid(50)\n",
    "\n",
    "stochastic_sampler = SDESampler(\n",
    "    rectified_flow=editing_rectified_flow,\n",
    "\ttime_grid=time_grid,\n",
    "    num_samples=1,\n",
    "    noise_scale=2.0,\n",
    ")\n",
    "\n",
    "prompt = \"a photo of a sitting tiger\"\n",
    "\n",
    "x_1 = stochastic_sampler.sample_loop(seed=0, prompt=prompt, guidance_scale=3.5).trajectories[-1]\n",
    "\n",
    "x_1_rec = flux_model.decode(x_1)\n",
    "plt.imshow(x_1_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid = flux_model.prepare_time_grid(50)\n",
    "\n",
    "editing_velocity_field.end_t = 0.15\n",
    "editing_velocity_field.eta_base = 0.9\n",
    "\n",
    "stochastic_sampler = SDESampler(\n",
    "    rectified_flow=editing_rectified_flow,\n",
    "\ttime_grid=time_grid,\n",
    "    num_samples=1,\n",
    "    noise_scale=10.0,\n",
    ")\n",
    "\n",
    "prompt = \"a sitting cat statue, with a reflective silver surface\"\n",
    "\n",
    "x_1 = stochastic_sampler.sample_loop(seed=0, prompt=prompt, guidance_scale=10.0).trajectories[-1]\n",
    "\n",
    "x_1_rec = flux_model.decode(x_1)\n",
    "plt.imshow(x_1_rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
