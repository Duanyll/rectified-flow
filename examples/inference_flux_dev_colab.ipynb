{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lqiang67/rectified-flow/blob/main/examples/inference_flux_dev_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df17A5FwaXgC"
      },
      "outputs": [],
      "source": [
        "!git clone https://lqiang67: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@github.com/lqiang67/rectified-flow.git\n",
        "%cd rectified-flow/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79zHDbwmaXgF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from diffusers import FluxPipeline\n",
        "from torch import Tensor\n",
        "from torchvision import transforms\n",
        "from IPython.display import clear_output\n",
        "\n",
        "DTYPE = torch.bfloat16\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=DTYPE)\n",
        "pipe.to(device)\n",
        "print(f\"Loaded pipeline to device {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrue2EdFaXgG"
      },
      "outputs": [],
      "source": [
        "from rectified_flow.models.flux_dev import FluxWrapper\n",
        "from rectified_flow.rectified_flow import RectifiedFlow\n",
        "\n",
        "height = 1025\n",
        "width = 1025\n",
        "\n",
        "flux_model = FluxWrapper(\n",
        "    pipeline=pipe,\n",
        "    height=height,\n",
        "    width=width,\n",
        "    dtype=DTYPE,\n",
        "    device=device,\n",
        "\tseed=0,\n",
        ")\n",
        "\n",
        "rf_func = RectifiedFlow(\n",
        "    data_shape=flux_model.data_shape,\n",
        "    model=flux_model,\n",
        "    interp=\"straight\",\n",
        "    source_distribution=flux_model.sample_source_distribution,\n",
        "    device=device,\n",
        "\tdtype=DTYPE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcTUqYhhaXgH"
      },
      "outputs": [],
      "source": [
        "from rectified_flow.samplers import rf_samplers_dict\n",
        "\n",
        "# Sample and store sampling info for several following samplers\n",
        "X_0 = rf_func.sample_source_distribution(batch_size=1)\n",
        "time_grid = flux_model.prepare_time_grid(num_steps=50)\n",
        "print(f\"X_0: {X_0.shape}\")\n",
        "print(f\"time_grid: {time_grid}\")\n",
        "\n",
        "def print_time_callback(sampler): # demo callback function, e.g. one-step prediction\n",
        "    \"\"\"A callback function to print the current time t, refreshing the Jupyter Notebook output.\"\"\"\n",
        "    clear_output(wait=True)\n",
        "    print(f\"Current time: {sampler.t:.4f}\")\n",
        "\n",
        "my_callback = [print_time_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcAyh0d-aXgI"
      },
      "outputs": [],
      "source": [
        "euler_sampler = rf_samplers_dict[\"euler\"](\n",
        "    rectified_flow=rf_func,\n",
        "    callbacks=my_callback,\n",
        ")\n",
        "\n",
        "euler_sampler.sample_loop(\n",
        "    X_0=X_0,\n",
        "    time_grid=time_grid,\n",
        "    prompt=\"A photo of a cat holding a camera\",\n",
        "    guidance_scale=3.5,\n",
        ")\n",
        "\n",
        "X_1 = euler_sampler.trajectories[-1]\n",
        "print(X_1.shape)\n",
        "\n",
        "img = flux_model.decode(X_1)\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjJrGjX5aXgI"
      },
      "outputs": [],
      "source": [
        "noise_refresh_sampler = rf_samplers_dict[\"noise_refresh\"](\n",
        "    rectified_flow=rf_func,\n",
        "    callbacks=my_callback,\n",
        ")\n",
        "\n",
        "noise_refresh_sampler.sample_loop(\n",
        "    X_0=X_0,\n",
        "    time_grid=time_grid,\n",
        "    prompt=\"A photo of a cat holding a camera\",\n",
        "    guidance_scale=3.5,\n",
        ")\n",
        "\n",
        "X_1 = noise_refresh_sampler.trajectories[-1]\n",
        "print(X_1.shape)\n",
        "\n",
        "img = flux_model.decode(X_1)\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gUl-pGCaXgI"
      },
      "outputs": [],
      "source": [
        "overshoot_sampler = rf_samplers_dict[\"overshooting\"](\n",
        "    rectified_flow=rf_func,\n",
        "    callbacks=my_callback,\n",
        ")\n",
        "\n",
        "overshoot_sampler.sample_loop(\n",
        "    X_0=X_0,\n",
        "    time_grid=time_grid,\n",
        "    prompt=\"A photo of a cat holding a camera\",\n",
        "    guidance_scale=3.5,\n",
        ")\n",
        "\n",
        "X_1 = overshoot_sampler.trajectories[-1]\n",
        "print(X_1.shape)\n",
        "\n",
        "img = flux_model.unpack_and_decode(X_1)\n",
        "plt.imshow(img)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}