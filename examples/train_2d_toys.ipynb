{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectified Flow: 2D Toy Example\n",
    "\n",
    "This notebook provides an example illustrating the basic concept of Rectified Flow and demonstrates training on a 2D toy example. For more details, refer to '[Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow](https://arxiv.org/abs/2209.03003).'\n",
    "\n",
    "Rectified Flow learns an ordinary differential equation (ODE), $ \\dot{Z}_t = v(Z_t, t) $, to transfer data from a source distribution, $ \\pi_0 $, to a target distribution, $ \\pi_1 $, given limited observed data points sampled from $ \\pi_1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1exIRI93Jzv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.distributions as dist\n",
    "\n",
    "from rectified_flow.utils import set_seed\n",
    "\n",
    "from rectified_flow.rectified_flow import RectifiedFlow\n",
    "\n",
    "set_seed(0)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Distributions $ \\pi_0 $ and $ \\pi_1 $\n",
    "\n",
    "In this section, we generate synthetic $ \\pi_0 $ and $ \\pi_1 $ as two Gaussian mixture models (GMM).\n",
    "\n",
    "We sample $50,000$ data points from each distribution and store them as `D0` and `D1`. Additionally, we store the labels for $ \\pi_1 $ to differentiate whether the points belong to the upper or lower part of the $\\pi_1$ GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.datasets.toy_gmm import TwoPointGMM\n",
    "\n",
    "n_samples = 50000\n",
    "pi_0 = TwoPointGMM(x=0.0, y=7.5, std=0.5, device=device)\n",
    "pi_1 = TwoPointGMM(x=15.0, y=7.5, std=0.5, device=device)\n",
    "D0 = pi_0.sample([n_samples])\n",
    "D1, labels = pi_1.sample_with_labels([n_samples])\n",
    "labels.tolist()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(r'Samples from $\\pi_0$ and $\\pi_1$')\n",
    "plt.scatter(D0[:, 0].cpu(), D0[:, 1].cpu(), alpha=0.5, label=r'$\\pi_0$')\n",
    "plt.scatter(D1[:, 0].cpu(), D1[:, 1].cpu(), alpha=0.5, label=r'$\\pi_1$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "## 1-Rectified Flow\n",
    "\n",
    "Given observed samples $X_0 \\sim \\pi_0$ and $X_1 \\sim \\pi_1$, the *rectified flow* induced by $(X_0, X_1)$ is the time-differentiable process $\\mathbf{Z} = \\{Z_t: t \\in [0, 1]\\}$ with the velocity field defined as:\n",
    "\n",
    "$$\n",
    "\\mathrm{d}Z_t = v(Z_t, t) \\, \\mathrm{d}t, \\quad t \\in [0, 1], \\quad \\text{starting from } Z_0 = X_0.\n",
    "$$\n",
    "\n",
    "Here, $v: \\mathbb{R}^d \\times [0, 1] \\to \\mathbb{R}^d$ is set in a way that ensures that $Z_1$ follows $\\pi_1$ when $Z_0 \\sim \\pi_0$.\n",
    "\n",
    "Denote $X_t = \\alpha_t \\cdot X_1 + \\beta_t \\cdot X_0$ as an interpolation of samples $X_0$ and $X_1$. The velocity field is given by:\n",
    "\n",
    "$$\n",
    "v(z, t) = \\mathbb{E}[ \\dot X_t \\mid X_t = z] = \\arg \\min_{v} \\int_0^1 \\mathbb{E}\\left[\\lVert  \\dot \\alpha_t X_1 + \\dot \\beta_t X_0 - v(X_t, t) \\rVert^2\\right] \\mathrm{d}t,\n",
    "$$\n",
    "where $\\alpha_t, \\beta_t$ are any differentiable functions of time $t$ that satisfy $\\alpha_0=\\beta_1=0$ and $\\alpha_1 = \\beta_0 = 1$.\n",
    "\n",
    "The default choice is the straight interpolation:\n",
    "$$\n",
    "X_t = t X_1 + (1-t) X_0, \\quad \\quad \\dot X_t = X_1 - X_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning a unconditional Rectified Flow\n",
    "\n",
    "We parameterize the velocity field using a small unconditional MLP $v_\\theta$.\n",
    "\n",
    "The model is then passed to the `RectifiedFlow` class. Since this is a 2D toy example, the data shape is `(2,)`, and we use the `\"straight\"` interpolation mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.models.toy_mlp import MLPVelocity\n",
    "\n",
    "model = MLPVelocity(2, hidden_sizes = [128, 128, 128]).to(device)\n",
    "\n",
    "rectified_flow = RectifiedFlow(\n",
    "    data_shape=(2,),\n",
    "    velocity_field=model,\n",
    "    interp=\"straight\",\n",
    "    source_distribution=pi_0,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the model samples data points from the source ($\\pi_0$) and target ($\\pi_1$) distributions to compute the loss for optimizing the velocity field:\n",
    "\n",
    "$$\n",
    "\\ell = \\min_{\\theta} \n",
    "\\int_0^1 \\mathbb{E}_{X_0 \\sim \\pi_0, X_1 \\sim \\pi_1} \\left [ \\left\\| (X_1 - X_0) - v_\\theta(X_t, t) \\right\\|^2 \\right ] \\mathrm{d}t, \n",
    "\\quad \\text{where} \\quad\n",
    "X_t = t X_1 + (1-t) X_0.\n",
    "$$\n",
    "\n",
    "The `get_loss` method computes the rectified flow loss using:\n",
    "- **Inputs**:\n",
    "  - `x_0`: Samples from $\\pi_0$.\n",
    "  - `x_1`: Samples from $\\pi_1$.\n",
    "  - `labels` (optional): Provides conditional information, e.g., GMM component idx.\n",
    "- **Steps**:\n",
    "  1. **Interpolation**: Computes intermediate states $X_t$ and derivatives $\\dot{X}_t$.\n",
    "  2. **Prediction**: Predicts $v_\\theta(X_t, t)$ using the velocity model.\n",
    "  3. **Loss**: Measures the loss between $v_\\theta(X_t, t)$ and $\\dot{X}_t$, with time-dependent weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "qqQwOYJFj5dw",
    "outputId": "b2f12485-d699-417a-b575-683f58fa95ad"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size = 1024\n",
    "\n",
    "losses = []\n",
    "\n",
    "for step in range(5000):\n",
    "\toptimizer.zero_grad()\n",
    "\tidx = torch.randperm(n_samples)[:batch_size]\n",
    "\tx_0 = D0[idx]\n",
    "\tx_1 = D1[idx]\n",
    "\t\n",
    "\tx_0 = x_0.to(device)\n",
    "\tx_1 = x_1.to(device)\n",
    "\t\n",
    "\tloss = rectified_flow.get_loss(x_0, x_1)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tlosses.append(loss.item())\n",
    "\n",
    "\tif step % 200 == 0:\n",
    "\t\tprint(f\"Epoch {step}, Loss: {loss.item()}\")\n",
    "    \n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the Euler method to solve the ODE with $N = 100$ steps to generate samples from 1-Rectified Flow.\n",
    "\n",
    "We can see trajectories are \"rewired\" at the intersection of linear interpolations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "2df4fiUtldJf",
    "outputId": "df915f27-8cd9-457c-bf30-a297979072e9"
   },
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import EulerSampler\n",
    "from rectified_flow.utils import visualize_2d_trajectories_plotly\n",
    "\n",
    "euler_sampler_1rf_unconditional = EulerSampler(\n",
    "    rectified_flow=rectified_flow,\n",
    "    num_steps=100,\n",
    "    num_samples=500,\n",
    ")\n",
    "\n",
    "euler_sampler_1rf_unconditional.sample_loop(seed=0)\n",
    "\n",
    "visualize_2d_trajectories_plotly(\n",
    "    trajectories_dict={\"1rf uncond\": euler_sampler_1rf_unconditional.trajectories},\n",
    "    D1_gt_samples=D1[:1000],\n",
    "    num_trajectories=200,\n",
    "\ttitle=\"Unconditional 1-Rectified Flow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euler_sampler_1rf_unconditional.sample_loop(num_steps=1, seed=0)\n",
    "\n",
    "visualize_2d_trajectories_plotly(\n",
    "    {\"1rf uncond one-step\": euler_sampler_1rf_unconditional.trajectories}, \n",
    "    D1[:1000],\n",
    "    num_trajectories=200,\n",
    "\ttitle=\"Unconditional 1-Rectified Flow, 1-step\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning a Conditional Rectified Flow\n",
    "\n",
    "The rectified flow model can be extended to include class conditioning. By passing class information $c \\in \\{0, 1\\}$ (e.g., for GMM components), the velocity field becomes class-dependent.\n",
    "\n",
    "$$\n",
    "\\ell = \\min_{\\theta}\n",
    "\\int_0^1 \\mathbb{E}_{X_0 \\sim \\pi_0, (X_1,c) \\sim \\pi_1} \\left [ \\left\\| (X_1 - X_0) - v_\\theta(X_t, t, c) \\right\\|^2 \\right ] \\mathrm{d}t,\n",
    "\\quad \\text{where} \\quad\n",
    "X_t = t X_1 + (1-t) X_0.\n",
    "$$\n",
    "\n",
    "In this case, $(X_1, c)\\sim \\pi_1$ is the distribution of data-label pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.models.toy_mlp import MLPVelocityConditioned\n",
    "\n",
    "model_cond = MLPVelocityConditioned(2, hidden_sizes = [128, 128, 128]).to(device)\n",
    "\n",
    "rectified_flow_cond = RectifiedFlow(\n",
    "    data_shape=(2,),\n",
    "    velocity_field=model_cond,\n",
    "    interp=\"straight\",\n",
    "    source_distribution=pi_0,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_cond.parameters(), lr=1e-3)\n",
    "batch_size = 1024\n",
    "\n",
    "losses = []\n",
    "\n",
    "for step in range(5000):\n",
    "\toptimizer.zero_grad()\n",
    "\tidx = torch.randperm(n_samples)[:batch_size]\n",
    "\tx_0 = D0[idx]\n",
    "\tx_1, cond = D1[idx], labels[idx]\n",
    "\t\n",
    "\tx_0 = x_0.to(device)\n",
    "\tx_1 = x_1.to(device)\n",
    "\tcond = torch.tensor(cond).to(device)\n",
    "\t\n",
    "\tloss = rectified_flow_cond.get_loss(x_0, x_1, labels=cond)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tlosses.append(loss.item())\n",
    "\n",
    "\tif step % 200 == 0:\n",
    "\t\tprint(f\"Epoch {step}, Loss: {loss.item()}\")\n",
    "    \n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By incorporating class information, the model can better capture the structure of conditional distributions. This ensures that the velocity fields for different classes (e.g., $c \\in \\{0, 1\\}$) remain distinct, avoiding intersections in the middle of trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import EulerSampler\n",
    "from rectified_flow.utils import visualize_2d_trajectories_plotly\n",
    "\n",
    "euler_sampler_1rf_conditional = EulerSampler(\n",
    "    rectified_flow=rectified_flow_cond,\n",
    "    num_steps=100,\n",
    "    num_samples=500,\n",
    ")\n",
    "\n",
    "cond = torch.zeros((500,), device=device)\n",
    "euler_sampler_1rf_conditional.sample_loop(seed=0, labels=cond)\n",
    "\n",
    "visualize_2d_trajectories_plotly(\n",
    "    {\"1rf cond\": euler_sampler_1rf_conditional.trajectories},\n",
    "    D1[:1000],\n",
    "    num_trajectories=200,\n",
    "    title=\"Conditional 1-Rectified Flow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflow for 2-Rectified Flow\n",
    "\n",
    "Now let's try the *reflow* procedure to get a straightened rectified flow, \n",
    "denoted as 2-Rectified Flow, by repeating the same procedure on with $(X_0,X_1)$ replaced by  $(Z_0^1, Z_1^1)$, where $(Z_0^1, Z_1^1)$ is the coupling simulated from 1-Rectified Flow.  \n",
    "\n",
    "We sample $50,000$ $Z_0^1$ and generate their corresponding $Z_1^1$ by simulating 1-Rectified Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_0 = rectified_flow.sample_source_distribution(batch_size=50000)\n",
    "\n",
    "Z_1 = euler_sampler_1rf_unconditional.sample_loop(x_0=Z_0, num_steps=1000).trajectories[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size = 1024\n",
    "\n",
    "losses = []\n",
    "\n",
    "for step in range(5000):\n",
    "\toptimizer.zero_grad()\n",
    "\tidx = torch.randperm(n_samples)[:batch_size]\n",
    "\tx_0 = Z_0[idx]\n",
    "\tx_1 = Z_1[idx]\n",
    "\t\n",
    "\tx_0 = x_0.to(device)\n",
    "\tx_1 = x_1.to(device)\n",
    "\t\n",
    "\tloss = rectified_flow.get_loss(x_0, x_1)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tlosses.append(loss.item())\n",
    "\n",
    "\tif step % 200 == 0:\n",
    "\t\tprint(f\"Epoch {step}, Loss: {loss.item()}\")\n",
    "    \n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euler_sampler_2rf = EulerSampler(\n",
    "    rectified_flow=rectified_flow,\n",
    "    num_samples=1000,\n",
    ")\n",
    "\n",
    "euler_sampler_2rf.sample_loop(num_steps=100, seed=0)\n",
    "\n",
    "visualize_2d_trajectories_plotly(\n",
    "    {\"2rf\": euler_sampler_2rf.trajectories}, \n",
    "    D1[:1000],\n",
    "    num_trajectories=200,\n",
    "    title=\"Reflow Trajectories, 100-step\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euler_sampler_2rf.sample_loop(num_steps=1, seed=0)\n",
    "\n",
    "visualize_2d_trajectories_plotly(\n",
    "    {\"2rf one-step\" :euler_sampler_2rf.trajectories}, \n",
    "    D1[:1000],\n",
    "    num_trajectories=200,\n",
    "    title=\"Reflow Trajectories, 1-step\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMWW2rwbL3siZ4bCQz0wyDE",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
